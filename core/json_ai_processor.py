#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSON AI Processor for Enhanced Code Editor
ูุนุงูุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุญุณู ููู JSON
"""

import json
import logging
import os
import re
from typing import Dict, Any, Optional, List
from PyQt6.QtCore import QObject, pyqtSignal, QThread
import google.generativeai as genai
from .ai_prompts import AIPrompts
from .unified_file_manager import UnifiedFileManager
logger = logging.getLogger(__name__)
class JSONAIProcessor(QObject):
    """ูุนุงูุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุญุณู ููู JSON"""

    # ุงูุฅุดุงุฑุงุช
    response_ready = pyqtSignal(dict)
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(str)
    file_creation_requested = pyqtSignal(str, str, str)  # ุงุณู ุงููููุ ุงููุญุชููุ ุงูููุน
    connection_status_changed = pyqtSignal(bool) # ุชูุตุฏุฑ True ุนูุฏ ุงูุงุชุตุงูุ False ุนูุฏ ุงููุดู

    def __init__(self, config, file_manager: UnifiedFileManager, parent=None):
        super().__init__(parent)
        self.config = config
        self.file_manager = file_manager
        self.model = None
        self.chat = None
        self.is_connected = False
        self.current_worker = None
        # ุฅุถุงูุฉ ูุชุบูุฑุงุช ูุชุฎุฒูู ุณูุงู ุงูููุฏ ุงูุญุงูู ูุงููุณุงุฑ
        self.current_code = ""
        self.current_file_path = ""
        
        # ุชููุฆุฉ ุงูุงุชุตุงู
        self.initialize_connection()
    def shutdown(self):
        """ุฅููุงู ุฃู ุนุงูู AI ูุดุท ุจุดูู ุณูุณ ุนูุฏ ุฅุบูุงู ุงูุชุทุจูู."""
        if self.current_worker and self.current_worker.isRunning():
            logger.info("JSONAIProcessor: Shutting down active AI worker.")
            self.current_worker.cancel() # ุงุทูุจ ูู ุงูุนุงูู ุฅูุบุงุก ุนููู
            # *** ูุฐุง ุงูุณุทุฑ ูู ุงูุฃูู ูุญู ูุดููุฉ ุงูุชุญุฐูุฑ ***
            # ุงูุชุธุฑ ุญุชู ูููู ุงูุฎูุท ุนููู ุชูุงูุงู ูุจู ุฃู ูุชู ุชุฏููุฑู.
            # ูุฐุง ูููุน ุฑุณุงูุฉ "Destroyed while thread is still running"
            self.current_worker.wait()
            logger.info("JSONAIProcessor: AI worker thread has finished.")
        else:
            logger.info("JSONAIProcessor: No active AI worker to shut down.")
    
    def initialize_connection(self):
        """ุชููุฆุฉ ุงูุงุชุตุงู ูุน Gemini AI"""
        try:
            api_key = self.config.get_gemini_api_key()
            if not api_key or api_key == "your_api_key_here":
                logger.warning("Gemini API key not configured")
                self.is_connected = False
                self.connection_status_changed.emit(False) # ุฅุตุฏุงุฑ ุงูุฅุดุงุฑุฉ: ูุดู ุงูุงุชุตุงู
                return False
            
            genai.configure(api_key=api_key)
            
            # ุฅุนุฏุงุฏ ุงููููุฐุฌ
            model_name = self.config.get('ai.model', 'gemini-2.0-flash')
            
            # ุงูุชุฃูุฏ ูู ุชุญููู ุงูููู ุฅูู ุฃุฑูุงู ุญููููุฉ (float/int)
            temperature = float(self.config.get('ai.temperature', 0.7))
            top_p = float(self.config.get('ai.top_p', 0.95))
            top_k = int(self.config.get('ai.top_k', 40))
            max_output_tokens = int(self.config.get('ai.max_tokens', 2048))

            generation_config = {
                'temperature': temperature,
                'top_p': top_p,
                'top_k': top_k,
                'max_output_tokens': max_output_tokens,
            }
            logger.info(f"JSONAIProcessor: Initializing Gemini model with config: {generation_config}")
            
            # ุงูุญุตูู ุนูู ุงูู system prompt
            system_prompt_text = AIPrompts.get_system_prompt()

            # ุชููุฆุฉ GenerativeModel ูุน system_instruction
            self.model = genai.GenerativeModel(
                model_name=model_name,
                generation_config=generation_config,
                system_instruction=system_prompt_text # ุชู ููู system_prompt ุฅูู ููุง
            )
            
            # ุจุฏุก ูุญุงุฏุซุฉ ุฌุฏูุฏุฉ ุจุฏูู system prompt ูู history
            self.chat = self.model.start_chat(history=[]) # ุชู ุฅุฒุงูุฉ system_prompt ูู history
            
            self.is_connected = True
            logger.info("JSON AI Processor connected successfully")
            self.connection_status_changed.emit(True) # ุฅุตุฏุงุฑ ุงูุฅุดุงุฑุฉ: ุชู ุงูุงุชุตุงู ุจูุฌุงุญ
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize JSON AI Processor: {e}", exc_info=True) # Log full traceback
            self.is_connected = False
            self.connection_status_changed.emit(False) # ุฅุตุฏุงุฑ ุงูุฅุดุงุฑุฉ: ูุดู ุงูุงุชุตุงู
            return False
    
    def process_user_input(self, user_input: str, current_code: str = "", file_path: str = "", project_files: List[str] = None):
        """ูุนุงูุฌุฉ ูุฏุฎูุงุช ุงููุณุชุฎุฏู ูุฅุฑุฌุงุน ุงุณุชุฌุงุจุฉ JSON"""
        logger.info(f"JSONAIProcessor: Received user input for processing. Input length: {len(user_input)}")
        if not self.is_connected:
            self.error_occurred.emit("ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุบูุฑ ูุชุตู")
            logger.error("JSONAIProcessor: AI is not connected, cannot process input.")
            return
        
        if self.current_worker and self.current_worker.isRunning():
            self.current_worker.cancel()
            self.current_worker.wait()
            logger.info("JSONAIProcessor: Cancelled previous worker.")
        
        # ุงุณุชุฎุฏุงู ุงูุณูุงู ุงููุฎุฒู ุฅุฐุง ูู ูุชู ุชูููุฑู ูุจุงุดุฑุฉ ูู ุงูุงุณุชุฏุนุงุก
        if not current_code:
            current_code = self.current_code
        if not file_path:
            file_path = self.current_file_path

        # ุชูุณูู ุงููุฏุฎูุงุช
        formatted_input = AIPrompts.format_user_input(user_input, current_code, file_path)
        logger.debug(f"JSONAIProcessor: Formatted input length: {len(formatted_input)}")
        
        # ุฅุถุงูุฉ ุณูุงู ุงููุดุฑูุน ุฅุฐุง ูุงู ูุชููุฑุงู
        if project_files:
            context = AIPrompts.get_context_prompt(project_files)
            formatted_input = context + "\n" + formatted_input
            logger.debug(f"JSONAIProcessor: Added project context. New input length: {len(formatted_input)}")
        
        # ุจุฏุก ุงููุนุงูุฌุฉ ูู ุฎูุท ูููุตู
        self.current_worker = JSONAIWorker(self.chat, formatted_input, self.file_manager)
        self.current_worker.response_ready.connect(self._handle_ai_response)
        self.current_worker.error_occurred.connect(self.error_occurred.emit)
        self.current_worker.progress_updated.connect(self.progress_updated.emit)
        self.current_worker.file_creation_requested.connect(self.file_creation_requested.emit)
        self.current_worker.finished.connect(self._worker_finished)
        self.current_worker.start()
        logger.info("JSONAIProcessor: JSONAIWorker started.")
    
    def process_general_query(self, query: str):
        """
        ูุนุงูุฌุฉ ุงุณุชุนูุงู ุนุงู ูู ุงููุณุชุฎุฏู.
        ูุฐู ุงูุฏุงูุฉ ุชูุณุชุฎุฏู ููุงุฌูุฉ ุจุณูุทุฉ ููุงุณุชุนูุงูุงุช ุงูุนุงูุฉ ุงูุชู ูุง ุชุชุทูุจ ุณูุงู ููุฏ ูุญุฏุฏ.
        """
        logger.info(f"JSONAIProcessor: Received general query: '{query}'")
        # ุงุณุชุฏุนุงุก ุงูุฏุงูุฉ ุงูุฃุณุงุณูุฉ process_user_input ูุน ููู ุงูุชุฑุงุถูุฉ ููููุฏ ูุงููุณุงุฑ
        # ููุง ุณูุชู ุงุณุชุฎุฏุงู current_code ู current_file_path ุงููุฎุฒูุฉ ุฅุฐุง ูู ูุชู ุชูุฑูุฑูุง
        self.process_user_input(user_input=query)

   
    def set_context(self, current_code: str, file_path: str, project_files: Optional[List[str]] = None):
        self.current_code = current_code
        self.current_file_path = file_path
        self.project_files_context = project_files
        logger.debug(f"JSONAIProcessor: Context updated. File: {file_path}, Code length: {len(current_code)}")
        # Make absolutely sure there is NO call to self.process_user_input() or starting a worker here.
        # This method should be passive.
    def _handle_ai_response(self, response: Dict[str, Any]):
        """ูุนุงูุฌุฉ ุงุณุชุฌุงุจุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
        logger.info(f"JSONAIProcessor: Handling AI response. Action: {response.get('action')}")
        try:
            action = response.get('action', '')
            
            # ูุนุงูุฌุฉ ุงูุฅุฌุฑุงุกุงุช ุงูุฎุงุตุฉ
            if action == 'create_file' and response.get('auto_create', False):
                file_name = response.get('file_name', 'new_file.txt')
                content = response.get('content', '')
                file_type = response.get('file_type', 'text')
                
                # ุฅูุดุงุก ุงูููู ุชููุงุฆูุงู
                success = self.file_manager.create_file_with_content(file_name, content, file_type)
                if success:
                    response['file_created'] = True
                    response['file_path'] = file_name
                    self.file_creation_requested.emit(file_name, content, file_type)
                    logger.info(f"JSONAIProcessor: Auto-created file: {file_name}")
                else:
                    response['error'] = f"ูุดู ูู ุฅูุดุงุก ุงูููู: {file_name}"
                    logger.error(f"JSONAIProcessor: Failed to auto-create file: {file_name}")
            elif action in ["add_code", "replace_code", "optimize_code", "add_comment"]:
                content = response.get("content", "") # Ensure content is always defined here
                if self.current_file_path:
                    current_content = self.file_manager.open_file(self.current_file_path)
                    if current_content is not None:
                        if action == 'add_code':
                            new_content = current_content + '\n\n' + content
                        elif action == 'add_comment':
                            new_content = current_content + '\n' + content
                        else: # replace_code, optimize_code
                            new_content = content
                        
                        success = self.file_manager.save_file(self.current_file_path, new_content)
                        if success:
                            response['file_updated'] = True
                            response['file_path'] = self.current_file_path
                            logger.info(f"JSONAIProcessor: File updated in-place: {self.current_file_path}")
                        else:
                            response['error'] = f"ูุดู ูู ุชุญุฏูุซ ุงูููู: {self.current_file_path}"
                            logger.error(f"JSONAIProcessor: Failed to update file in-place: {self.current_file_path}")
                    else:
                        response['error'] = f"ูุดู ูู ูุฑุงุกุฉ ุงูููู ุงูุญุงูู: {self.current_file_path}"
                        logger.error(f"JSONAIProcessor: Failed to read current file for in-place update: {self.current_file_path}")
                else:
                    response['error'] = "ูุง ููุฌุฏ ููู ุญุงูู ูุชุญุฏูุซู."
                    logger.error("JSONAIProcessor: No current file path for in-place update.")
            
            self.response_ready.emit(response)
            logger.info("JSONAIProcessor: Emitted response_ready signal.")
            
        except Exception as e:
            logger.error(f"JSONAIProcessor: Error handling AI response: {e}", exc_info=True)
            self.error_occurred.emit(f"ุฎุทุฃ ูู ูุนุงูุฌุฉ ุงูุงุณุชุฌุงุจุฉ: {str(e)}")
    
    def _worker_finished(self):
        """ุงูุชุนุงูู ูุน ุงูุชูุงุก ุงูุนุงูู"""
        logger.info("JSONAIProcessor: JSONAIWorker finished.")
        if self.current_worker:
            if self.current_worker.isRunning():
               logger.debug("JSONAIProcessor: Waiting for worker to finish before deleting.")
               self.current_worker.wait()
            self.current_worker.deleteLater()
            self.current_worker = None

    
    def is_busy(self):
        """ูุญุต ูุง ุฅุฐุง ูุงู ุงููุนุงูุฌ ูุดุบููุงู"""
        return self.current_worker is not None and self.current_worker.isRunning()
    
    def cancel_current_operation(self):
        """ุฅูุบุงุก ุงูุนูููุฉ ุงูุญุงููุฉ"""
        if self.current_worker and self.current_worker.isRunning():
            logger.info("JSONAIProcessor: Cancelling current operation.")
            self.current_worker.cancel()
            self.current_worker.wait()

    def is_available(self) -> bool:
        """
        ูุญุต ูุง ุฅุฐุง ูุงู ูุนุงูุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุชุงุญุงู (ูุชุตูุงู).
        ูุฐู ุงูุฏุงูุฉ ุชูุณุชุฎุฏู ุจูุงุณุทุฉ EnhancedMainWindow ููุชุญูู ูู ุญุงูุฉ ุงูุงุชุตุงู.
        """
        return self.is_connected

class JSONAIWorker(QThread):
    """ุนุงูู ูุนุงูุฌุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ุฎูุท ูููุตู"""
    
    response_ready = pyqtSignal(dict)
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(str)
    file_creation_requested = pyqtSignal(str, str, str)
    
    def __init__(self, chat, user_input: str, file_manager: UnifiedFileManager):
        super().__init__()
        self.chat = chat
        self.user_input = user_input
        self.file_manager = file_manager
        self.is_cancelled = False
        logger.debug("JSONAIWorker: Initialized.")
    
    def run(self):
        """ุชุดุบูู ุงููุนุงูุฌุฉ"""
        try:
            self.progress_updated.emit("ุฌุงุฑู ูุนุงูุฌุฉ ุงูุทูุจ...")
            logger.info("JSONAIWorker: Sending message to Gemini AI.")
            
            # ุฅุฑุณุงู ุงูุทูุจ ุฅูู Gemini
            response = self.chat.send_message(self.user_input)
            logger.info(f"JSONAIWorker: Received raw AI response. Text length: {len(response.text) if response.text else 0}")
            logger.debug(f"JSONAIWorker: Raw AI response text: \n{response.text}") # Log raw response for debugging
            
            if self.is_cancelled:
                logger.info("JSONAIWorker: Operation cancelled during AI response.")
                return
            
            self.progress_updated.emit("ุฌุงุฑู ุชุญููู ุงูุงุณุชุฌุงุจุฉ...")
            
            # ุชุญููู ุงูุงุณุชุฌุงุจุฉ
            parsed_response = self._parse_ai_response(response.text)
            logger.info(f"JSONAIWorker: Parsed AI response. Action: {parsed_response.get('action')}, Content length: {len(parsed_response.get('content', ''))}")
            logger.debug(f"JSONAIWorker: Parsed AI response: {parsed_response}") # Log parsed response for debugging
            
            if not self.is_cancelled:
                self.response_ready.emit(parsed_response)
                logger.info("JSONAIWorker: Emitted response_ready from worker.")
                
        except Exception as e:
            if not self.is_cancelled:
                logger.error(f"JSONAIWorker: Error in JSON AI Worker: {e}", exc_info=True)
                self.error_occurred.emit(f"ุฎุทุฃ ูู ูุนุงูุฌุฉ ุงูุทูุจ: {str(e)}")
            else:
                logger.info("JSONAIWorker: Error occurred but operation was cancelled.")
    
    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        """ุชุญููู ุงุณุชุฌุงุจุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุชุญููููุง ุฅูู JSON"""
        logger.debug(f"JSONAIWorker: Parsing AI response text:\n{response_text}")
        try:
            # ูุญุงููุฉ ุงุณุชุฎุฑุงุฌ JSON ูู ุงููุต
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group()
                logger.debug(f"JSONAIWorker: Extracted JSON string: {json_str}")
                # ุชูุธูู ุงููุต
                json_str = self._clean_json_string(json_str)
                logger.debug(f"JSONAIWorker: Cleaned JSON string: {json_str}")
                parsed = json.loads(json_str)
                logger.debug(f"JSONAIWorker: Successfully parsed JSON: {parsed}")
                
                # ุงูุชุญูู ูู ูุฌูุฏ ุงูุญููู ุงููุทููุจุฉ
                if 'action' not in parsed:
                    parsed['action'] = 'add_comment'
                    logger.warning("JSONAIWorker: 'action' key missing in parsed JSON, defaulting to 'add_comment'.")
                if 'content' not in parsed:
                    parsed['content'] = response_text
                    logger.warning("JSONAIWorker: 'content' key missing in parsed JSON, defaulting to raw response text.")
                if 'explanation' not in parsed:
                    parsed['explanation'] = 'ุชู ูุนุงูุฌุฉ ุงูุทูุจ'
                    logger.warning("JSONAIWorker: 'explanation' key missing in parsed JSON, defaulting to 'ุชู ูุนุงูุฌุฉ ุงูุทูุจ'.")
                
                return parsed
            else:
                logger.warning("JSONAIWorker: No JSON object found in AI response. Creating fallback response.")
                # ุฅุฐุง ูู ูุชู ุงูุนุซูุฑ ุนูู JSONุ ุฅูุดุงุก ุงุณุชุฌุงุจุฉ ุงูุชุฑุงุถูุฉ
                return self._create_fallback_response(response_text)
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSONAIWorker: Failed to parse JSON response: {e}. Creating fallback response.", exc_info=True)
            return self._create_fallback_response(response_text)
        except Exception as e:
            logger.error(f"JSONAIWorker: Unexpected error parsing AI response: {e}. Creating error response.", exc_info=True)
            return {
                'action': 'error',
                'content': f'ุฎุทุฃ ูู ุชุญููู ุงูุงุณุชุฌุงุจุฉ: {str(e)}',
                'explanation': 'ูุดู ูู ุชุญููู ุงุณุชุฌุงุจุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู'
            }
    
    def _clean_json_string(self, json_str: str) -> str:
        """ุชูุธูู ูุต JSON ูู ุงูุฃุฎุทุงุก ุงูุดุงุฆุนุฉ ูุงููุนูุฏุฉ."""
        logger.debug(f"JSONAIWorker: Attempting to clean JSON string:\n{json_str}")
        
        # 1. ุฅุฒุงูุฉ ุฃู ูุต ูุจู ุฃูู ููุณ ููุชูุญ { ูุจุนุฏ ุขุฎุฑ ููุณ ูุบูู }
        # ูุฐุง ูุฒูู ุฃู ูุต ุฒุงุฆุฏ ูุฏ ูุฑุณูู AI ุฎุงุฑุฌ ูุงุฆู JSON.
        json_match = re.search(r'\{.*\}', json_str, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            logger.debug(f"JSONAIWorker: Extracted main JSON block: {json_str[:200]}...") # Log start of block
        else:
            logger.warning("JSONAIWorker: No complete JSON object found in string during cleaning.")
            return json_str # Return as is if no JSON block is found

        # 2. ุฅุฒุงูุฉ ุงูุชุนูููุงุช ุจุฃุณููุจ JavaScript (//) ุฃู Python (#)
        # ุชุฃูุฏ ูู ุนุฏู ุฅุฒุงูุฉ // ุงูุชู ูุฏ ุชููู ุฌุฒุกูุง ูู URL ุฏุงุฎู ูููุฉ ูุตูุฉ
        json_str = re.sub(r'(?<![:"\w])//.*', '', json_str) # ูุฒูู // ุฅูุง ุฅุฐุง ุณุจูุชูุง : " ุฃู ุญุฑู
        json_str = re.sub(r'(?<![:"\w])#.*', '', json_str) # ูุฒูู # ุฅูุง ุฅุฐุง ุณุจูุชูุง : " ุฃู ุญุฑู
        
        # 3. ุฅุฒุงูุฉ ุงูุฃุณุทุฑ ุงูุฌุฏูุฏุฉ ุบูุฑ ุงูููุฑุจุฉ ุฏุงุฎู ุงููุตูุตุ ูุงุณุชุจุฏุงููุง ุจู \n ููุฑุจุฉ
        # ูุฐุง ูููุน ุงูุฃุณุทุฑ ุงูุฌุฏูุฏุฉ ูู ุงูููู ุงููุตูุฉ ูู ูุณุฑ JSON
        # (ุ <!) \ "ุชุทุงุจู ุญุฑู ุงูุณุทุฑ ุงูุฌุฏูุฏ ููุท ุฅุฐุง ูู ูุณุจูู ุฎุท ูุงุฆู ุนูุณู (\)
        json_str = re.sub(r'(?<!\\)\n', '\\n', json_str)
        
        # 4. ุฅุตูุงุญ ุงูููุงุตู ุงูููููุฏุฉ ุจูู ุงูุฃุฒูุงุฌ (key-value)
        # ูุจุญุซ ุนู ุนูุงูุฉ ุงูุชุจุงุณ ูุชุจูุนุฉ ุจูุณุงูุงุช ูุฃุณุทุฑ ุฌุฏูุฏุฉ ุซู ุนูุงูุฉ ุงูุชุจุงุณ ุฃุฎุฑูุ ููุถูู ูุงุตูุฉ
        # ูุฏ ูุญุชุงุฌ ูุฐุง ุฅูู ุชุนุฏูู ุฏููู ุจูุงุกู ุนูู ุงูุฃุฎุทุงุก ุงููุนููุฉ
        json_str = re.sub(r'("\s*?\n?\s*?")\s*(")', r'\1,\2', json_str)
        
        # 5. ุงูุชุนุงูู ูุน ุงูููุงุตู ุงูุฒุงุฆุฏุฉ ูู ุงูููุงูุฉ (ููุณ ุจุงูุถุฑูุฑุฉ ููุง ูููู ูููุฏ)
        json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
        
        # 6. ุฅุฒุงูุฉ ุฃู ุฃุณุทุฑ ูุงุฑุบุฉ ุฅุถุงููุฉ ูุฏ ุชููู ูุงุชุฌุฉ ุนู ุงูุชูุธูู
        json_str = os.linesep.join([s for s in json_str.splitlines() if s.strip()])

        logger.debug(f"JSONAIWorker: Finished cleaning JSON string.")
        return json_str

    
    def _create_fallback_response(self, response_text: str) -> Dict[str, Any]:
        """ุฅูุดุงุก ุงุณุชุฌุงุจุฉ ุงุญุชูุงุทูุฉ ุฅุฐุง ูุดู ุชุญููู JSON"""
        logger.info(f"JSONAIWorker: Creating fallback response for text length: {len(response_text)}")

    # ๐ ูุฐุง ุงูุฌุฒุก ุณูุชู ุฅุฒุงูุชู ุฃู ุชุนุฏููู ููุชุฌูุจ ุงูุชุฎููู ุงูุชููุงุฆู ูุฅูุดุงุก ุงูููู.
    # ูุง ุชุญุงูู ุชุฎููู "ุฅูุดุงุก ููู" ูู ูููุงุช ููุชุงุญูุฉ ุนุงูุฉ.
    # ุฅุฐุง ููุช ุชุฑูุฏ ูุฐุง ุงูุณูููุ ุงุฌุนูู ุฃูุซุฑ ุฏูุฉ ุฃู ูุฑุชุจุทุงู ุจุณูุงู ุงูุทูุจ ุงูุฃุตูู.

    # ุงุณุชุฌุงุจุฉ ุงูุชุฑุงุถูุฉ (ุงูุชุฑุถ ุฃู ุงูุบุงูุจูุฉ ุงูุนุธูู ูู ุงูุงุณุชุฌุงุจุงุช ุงูุชู ูุง ุชูููู
    # ูููู ุฃู ุชูุถุงู ูุชุนูููุงุช ุฃู ุงุณุชุฌุงุจุงุช ุนุงูุฉ).
        logger.info("JSONAIWorker: Fallback: Defaulting to general_response action (or add_comment).")
        return {
        'action': 'general_response', # ุฃู 'add_comment' ุญุณุจ ุชูุถููู
        'content': response_text, # ููุง ููููู ุฅุฑุฌุงุน ุงููุต ุงูุฎุงู ูุงููุงู
        'explanation': 'ูู ูุชููู AI ูู ุชูุฏูู ุงุณุชุฌุงุจุฉ ููุธูุฉุ ุชู ุฅุธูุงุฑ ุงููุต ุงูุฎุงู.'
    }
    
    def cancel(self):
       """ุฅูุบุงุก ุงูุนูููุฉ"""
       logger.info("JSONAIWorker: Cancel flag set to True.")
       self.is_cancelled = True